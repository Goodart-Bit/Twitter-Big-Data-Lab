{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator\n",
    "from tweepyclient import TweepyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepyclient.TweepyClient at 0x1e9228c4510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bearer_token = config.BEARER_TOKEN\n",
    "tweepyClient = TweepyClient(bearer_token)\n",
    "tweepyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_csv(text):\n",
    "    return text.replace(',',' ').replace(\"\\n\",' ') #Data must be cleaned for the CSV to be readed clearly \n",
    "\n",
    "\n",
    "def save_tweets(tweet_list, data=[], columns=['id', 'tweet', 'entidad', 'dominio']):\n",
    "    for tweet in tweet_list:\n",
    "        entity = ''\n",
    "        domain = ''\n",
    "        for context_annotation in tweet.context_annotations:\n",
    "            entity = context_annotation['entity']['name']\n",
    "            domain = context_annotation['domain']['name']\n",
    "        cleaned_text = format_for_csv(tweet.text)\n",
    "        data.append([tweet.id, cleaned_text, entity, domain])\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "def translate(word, dest='en', translator = Translator()):\n",
    "    translation = translator.translate(word, dest)\n",
    "    return translation.text\n",
    "\n",
    "def get_tweets_sentiment(tweet_list, data=[], columns=['id', 'tweet', 'sentimiento', 'entidad'], sia = SentimentIntensityAnalyzer()):\n",
    "    for tweet in tweet_list:\n",
    "        entity = ''\n",
    "        translated_text = translate(tweet.text)  #Sentiment analysis only works in english\n",
    "        for context_annotation in tweet.context_annotations:\n",
    "            entity = context_annotation['entity']['name']\n",
    "        # SENTIMENT ONLY WORKS IN ENGLISH\n",
    "        sentiment_dict = sia.polarity_scores(translated_text)\n",
    "        positive = sentiment_dict[\"pos\"]\n",
    "        negative = sentiment_dict[\"neg\"]\n",
    "        bias = 'neutral'\n",
    "        if (positive > negative):\n",
    "            bias = 'positivo'\n",
    "        elif(positive < negative):\n",
    "            bias = 'negativo'\n",
    "        else:\n",
    "            bias = 'neutral'\n",
    "        cleaned_text = format_for_csv(tweet.text)\n",
    "        data.append([tweet.id, cleaned_text, bias, entity])\n",
    "    # SENTIMENT ANALYSIS DATAFRAME\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta #3: Sintomas mÃ¡s consultados en Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(sintomas OR sintoma) context:123.1220701888179359745 lang:es -is:retweet\"\n",
    "symptom_tweets = tweepyClient.search_tweets(query, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tweets_df = save_tweets(symptom_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tweets_df.to_csv('./data/symptom_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(dioxido OR azitromicina OR ivermectina) context:123.1220701888179359745 -is:retweet\"\n",
    "medicine_tweets = tweepyClient.search_tweets(query, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sp_tweets_df \u001b[39m=\u001b[39m get_tweets_sentiment(medicine_tweets)\n\u001b[0;32m      2\u001b[0m sp_tweets_df\n",
      "Cell \u001b[1;32mIn [40], line 37\u001b[0m, in \u001b[0;36mget_tweets_sentiment\u001b[1;34m(tweet_list, data, columns, sia)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m         bias \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mneutral\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 37\u001b[0m     cleaned_text \u001b[39m=\u001b[39m format_for_csv(tweet)\n\u001b[0;32m     38\u001b[0m     data\u001b[39m.\u001b[39mappend([tweet\u001b[39m.\u001b[39mid, cleaned_text, bias, entity])\n\u001b[0;32m     39\u001b[0m \u001b[39m# SENTIMENT ANALYSIS DATAFRAME\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [40], line 2\u001b[0m, in \u001b[0;36mformat_for_csv\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_for_csv\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m text\u001b[39m.\u001b[39;49mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\tweepy\\mixins.py:35\u001b[0m, in \u001b[0;36mDataMapping.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[name]\n\u001b[0;32m     34\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sp_tweets_df = get_tweets_sentiment(medicine_tweets)\n",
    "sp_tweets_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
