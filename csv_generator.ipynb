{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from googletrans import Translator\n",
    "from tweepyclient import TweepyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tweepyclient.TweepyClient at 0x1e9228c4510>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bearer_token = config.BEARER_TOKEN\n",
    "tweepyClient = TweepyClient(bearer_token)\n",
    "tweepyClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_csv(text):\n",
    "    return text.replace(',',' ').replace(\"\\n\",' ') #Data must be cleaned for the CSV to be readed clearly \n",
    "\n",
    "\n",
    "def save_tweets(tweet_list, data=[], columns=['id', 'tweet', 'entidad', 'dominio']):\n",
    "    for tweet in tweet_list:\n",
    "        entity = ''\n",
    "        domain = ''\n",
    "        for context_annotation in tweet.context_annotations:\n",
    "            entity = context_annotation['entity']['name']\n",
    "            domain = context_annotation['domain']['name']\n",
    "        cleaned_text = format_for_csv(tweet.text)\n",
    "        data.append([tweet.id, cleaned_text, entity, domain])\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "def translate(word, dest='en', translator = Translator()):\n",
    "    translation = translator.translate(word, dest)\n",
    "    return translation.text\n",
    "\n",
    "def get_tweets_sentiment(tweet_list, data=[], columns=['id', 'tweet', 'sentimiento', 'entidad'], sia = SentimentIntensityAnalyzer()):\n",
    "    for tweet in tweet_list:\n",
    "        entity = ''\n",
    "        translated_text = translate(tweet.text)  #Sentiment analysis only works in english\n",
    "        for context_annotation in tweet.context_annotations:\n",
    "            entity = context_annotation['entity']['name']\n",
    "        # SENTIMENT ONLY WORKS IN ENGLISH\n",
    "        sentiment_dict = sia.polarity_scores(translated_text)\n",
    "        positive = sentiment_dict[\"pos\"]\n",
    "        negative = sentiment_dict[\"neg\"]\n",
    "        bias = 'neutral'\n",
    "        if (positive > negative):\n",
    "            bias = 'positivo'\n",
    "        elif(positive < negative):\n",
    "            bias = 'negativo'\n",
    "        else:\n",
    "            bias = 'neutral'\n",
    "        cleaned_text = format_for_csv(tweet.text)\n",
    "        data.append([tweet.id, cleaned_text, bias, entity])\n",
    "    # SENTIMENT ANALYSIS DATAFRAME\n",
    "    return pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta #3: Sintomas mÃ¡s consultados en Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(sintomas OR sintoma) context:123.1220701888179359745 lang:es -is:retweet\"\n",
    "symptom_tweets = tweepyClient.search_tweets(query, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tweets_df = save_tweets(symptom_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tweets_df.to_csv('./data/symptom_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"(dioxido OR azitromicina OR ivermectina) context:123.1220701888179359745 -is:retweet\"\n",
    "medicine_tweets = tweepyClient.search_tweets(query, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tweets_df = get_tweets_sentiment(medicine_tweets)\n",
    "sp_tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_tweets_df.to_csv('./data/4medicina_alternativa.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
